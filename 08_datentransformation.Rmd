---
title: "Datentransformation Advanced"
author: CorrelAid e.V.
date: "`r Sys.Date()`"
authors:
  - Zoé Wolter
  - Jonas Lorenz
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    theme: flatly
    css: www/style.css
    includes:
      after_body: ./www/favicon.html
    language: de
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(learnr)
library(gradethis)
library(forcats)
 
source("R/setup/gradethis-setup.R")
source("R/setup/tutorial-setup.R")
# Read app parameters
params <- yaml::yaml.load_file("www/app_parameters.yml")

# Benötigte Daten laden
source("R/setup/functions.R")
data_raw <- get_data_raw()
community <- get_community()
plastics_processed <- get_pl_proc()
audit <- get_audit()
wb_areas <- get_wb_areas()
wb_processed <- process_wb_areas(wb_data = wb_areas)
```

```{r results='asis'}
cat(get_license_note(rmarkdown::metadata$title, rmarkdown::metadata$authors))
```

Nachdem wir uns in der vergangenen Woche mit den Funktionen des **dplyr-Packages** die Grundlagen der Datentransformation angeschaut haben, werden wir nun einen Schritt weiter gehen und uns mit den **fortgeschrittenen Methoden der Datentranformation** beschäftigen. Wir werden uns überlegen, wie wir mit fehlenden Werten umgehen und Datensätze zusammenfügen können - und was versteckt sich eigentlich hinter dem Begriff "Pivoting"? Finden wir's heraus!

---

# **Umgang mit fehlenden Werten (NAs)**

Aus dem `dplyr`-Package kennen wir nun die verschiedenen Funktionen, mit deren Hilfe wir Variablen und Beobachtungen auswählen, filtern oder verändern können. Dabei setzen wir voraus, dass die Daten, die wir tranformieren möchten, auch tatsächlich in unserem Datensatz vorhanden sind. Doch was, wenn uns bestimmte Daten fehlen?

## **Schritt 1: Überprüfung**

Zunächst einmal müssen wir natürlich unsere Daten importieren - wir haben das an dieser Stelle breits einmal für Euch gemacht. Anschließend sollten wir **überprüfen**, ob denn tatsächlich alle Daten vorliegen oder Werte fehlen. Schließlich müssen wir herausfinden, wo Handlungsbedarf ist und wo wir direkt weitermachen können. Dafür checken wir mithilfe der **`sum()`**-Funktion einzelne Werte in unseren beiden Datensätzen, die wir vergangene Woche erstellt haben. <br>

Versucht zuerst einmal, die Summe für die Variable `n_pieces` im Datensatz `community` zu berechnen.

``` {r 08mean_na1, exercise = TRUE}
# Berechnung der Summe
sum(community$n_pieces)
```

Sieht gut aus - im Datensatz `community` sind keine fehlenden Werte enthalten, die bei der Berechnung der Summe stören könnten! Versucht das gleiche jetzt mal für den `audit`-Datensatz in folgendem Codeblock:

``` {r exercise_08mean_na2, exercise = TRUE}
# Hier Euer Code!

```

```{r exercise_08mean_na2-solution}
# Berechnung der Summe
sum(audit$n_pieces)
```

```{r exercise_08mean_na2-check}
grade_this_code()
```

Ups - wir erhalten ein NA. Das steht für "**N**ot **A**vailable" (zu dt. "nicht verfügbar"). Mit diesem Ausdruck gibt uns R das Zeichen, dass **ein (oder mehrere) Wert(e) fehlen** und die gewünschte Berechnung somit nicht ausgeführt werden kann. Wir wissen nun also schon einmal, dass im Datensatz `audit` fehlende Werte für die Variable `n_pieces`vorliegen. Noch wissen wir nicht, um wie viele fehlende Werte es sich dabei handelt, aber auch das können wir herausfinden - versucht das doch einmal selbst! <br>

*Tipp: Experimentiert mit der Funktion `summary()`!*

``` {r exercise_08mean_na3, exercise = TRUE}
# Hier Euer Code!

```

``` {r exercise_08mean_na3-solution}
# NAs bestimmen
summary(audit)
```

``` {r exercise_08mean_na3-check}
grade_this_code()
```

Sehr gut! Uns wird neben den üblichen Kennzahlen (Minumum, Maximum, Median, etc.) auch die Anzahl der **NAs** angegeben: In diesem Fall betrifft das 11.821 Werte. Klingt erst einmal nach sehr viel, aber trotzdem wollen wir in solchen Fällen durchaus statistische Kennzahlen berechnen. Wie das funktioniert, schauen wir uns jetzt an! <br>

## **Schritt 2: Berücksichtigung**

Denn trotz der fehlenden Werte, können wir in R die statistischen Kennzahlen berechnen. Dafür müssen wir R allerdings explizit sagen, dass die **NAs bei der Berechnung ignoriert** werden sollen. Das funktioniert über das zusätzliche Argument **`na.rm = TRUE`**, das wir einfach an die Funktion anhängen - vielleicht habt Ihr das in den vorherigen Übungen schon einmal gesehen:

``` {r 08mean_na4, exercise = TRUE}
# Berechnung der Summe unter Ausschluss der NAs
sum(audit$n_pieces, na.rm = TRUE)
```

Perfekt - jetzt weiß R, dass die entsprechenden **NAs ignoriert** werden sollen! Neben dieser einen Möglichkeit, gibt es noch viele weitere Wege, NA's in Datensätzen zu entdecken und zu filtern - versucht dafür mal den folgenden Codeblock zu verstehen: 

``` {r 08mean_na5, exercise = TRUE}
# Anzahl an fehlenden Werten (is.na gibt für eine Beobachtung TRUE (1) oder FALSE (0) zurück, deshalb können wir das hier aufsummieren)
na_count <- sum(is.na(audit$n_pieces))

# Auflisten von Beobachtungen, die fehlende Werte haben
na_rows <- audit[!complete.cases(audit$n_pieces), ]
na_rows <- which(is.na(audit$n_pieces))

# Neuer Datensatz ohne fehlende Werte
new_df <- na.omit(audit)
```

Für die Variable `n_pieces`in unserem `audit` Datensatz summieren wir also zunächst alle fehlenden Werte und listen die betroffenen Beobachtungen anschließend aus. Auf Basis dieser Transformation können wir dann einen neuen Datensatz ohne die fehlenden Werte erstellen. Die Funktion `**na.omit()**` entfernt dabei alle Zeilen oder Beobachtungen, die fehlende Werte (NA) enthalten, sodass nur vollständige Daten(sätze) übernommen werden. 

## **Besonderheiten**

Der Umgang mit fehlenden Werten ist allerdings nicht immer gleich, denn manchmal können diese Werte nicht einfach so ausgeschlossen werden, weil das sonst die **Aussagekraft unserer Analysen** beeinträchtigen würde. Bei [Allison 2010](https://statisticalhorizons.com/wp-content/uploads/Allison_MissingData_Handbook.pdf){target="_blank"} findet Ihr eine gute Übersicht gängiger Herausforderungen und Lösungen. Unser Tipp: Schon bei der Datenerhebung ansetzen und von Beginn an auf genau solche Vorkommnisse prüfen, sodass Ihr rechtzeitig reagieren könnt.

Häufig kommt es zudem vor, dass **fehlende Werte nicht als "NAs" codiert** sind: Wie Ihr vielleicht schon mal gesehen habt, werden fehlende Werte häufig auch als **“N/A”, “N A”, und “Not Available”, oder -99, oder -1** (oder in unserem Fall: "EMPTY") angegeben. Deshalb schauen wir vor der Datenbereinigung und -analyse immer ins zugehörige **Codebuch** des Datensatzes, in dem die Codierung der Variablen erläutert wird. Ansonsten berechnen wir möglicherweise einen Mittelwert, in den fälschlicherweise diese Zahlen einfließen. Aber auch in einem solchen Fall können wir uns wieder auf das `dplyr`-Package verlassen, das eine einfache Lösung parat hat: Die Funktion **`dplyr::na_if()`**. Diese wenden wir mithilfe von **`dplyr::mutate_all()`** auf alle Spalten an:

``` {r 08mean_na6, exercise = TRUE}
# Erstellung eines Beispieldataframes mit NAs als "NA" und "-99"
df <- tibble::tribble(
  ~name,              ~x,  ~y,           ~z,  
  "Person 1",         1,   -99,          6.7, 
  "Person 2",         3,   NA,           -99,
  "Person 3",         NA,  0.76,         -1.6
  )

# Definition der NAs
df2 <- df %>% 
  dplyr::mutate_all(dplyr::na_if, -99)

# Erste fünf Zeilen anzeigen
head(df2)
```

Wir sehen, dass alle Werte, die uns zuvor als *-99* ausgegeben wurden, nun ebenfalls als *NAs* codiert sind. 

---

# **Pivoting**

Das **Pivoting von Daten** (zu dt. schwenken) ist eine weitere Möglichkeit, um unsere Daten zu transformieren. Das Pivoting geht dabei über die Bereinigung und das Filtern von Werten im Datensatz hinaus, da wir die gesamte **Form eines Datensatzes verändern**, indem wir die Spalten und Zeilen neu anordnen. Wir können also Objekte und die damit verbundenen Informationen von den Spalten in die Zeilen (bzw. von den Zeilen in die Spalten) bewegen oder die Reihenfolge der Objekte in den Spalten und Zeilen verändern. Diese Form der Datentransformation ist nicht zwingend notwendig, aber manchmal durchaus sinnvoll, da manche Datensatze dadurch lesbarer werden - ein kleines Beispiel seht ihr [hier](https://www2.microstrategy.com/producthelp/Current/BasicReporting/WebHelp/Lang_1033/Content/BasicReporting/Pivoting_data.htm){target="_blank"}. <br> 

In R können wir zwei Funktionen des `tidyr`-Packages nutzen, um unseren Datensatz zu pivotieren: `pivot_longer()` und `pivot_wider`. <br>
Mit der Funktion **`pivot_longer()`** können wir Datensätze **verlängern** indem wir die Spaltenanzahl reduzieren und die Zeilenanzahl erhöhen. Daher wird die Funktion vor allem dafür verwendet, chaotische Datensätze zu bereinigen und einfache Vergleiche vorzunehmen. Wie das in der Realtiät aussehen kann, könnt Ihr auch noch einmal [hier](https://tidyr.tidyverse.org/articles/pivot.html#longer){target="_blank"} nachlesen. <br>
Im Gegensatz dazu können wir mit der Funktion **`pivot_wider()`** Datensätze **breiter machen**, indem wir die Spaltenanzahl erhöhen und die Zeilenanzahl reduzieren. Das kann durchaus nützlich sein, wenn wir Daten in Form von Tabellen für eine Präsentation vorbereiten möchten - tatsächlich wird diese Funktion aber eher selten verwendet. Mehr dazu findet Ihr ebenfalls [hier](https://tidyr.tidyverse.org/articles/pivot.html#wider){target="_blank"}.<br>

Auch in unserem `audit` Datensatz könnte das Pivoting hilfreich sein: In diesem Datensatz gibt es nämlich eine Reihe kryptischer Variablen, die für die **Plastikarten** stehen, aus denen der gesammelte Müll besteht. Um den Datensatz zu bereinigen, müssen wir beispielsweise noch die verschiedenen Plastikarten so transformieren, dass sie als eine einzige Variable **`plastic_type`** im Datensatz vorkommen:

``` {r 08pivot_longer, exercise = TRUE}
# Ihr nehmt Euren Datensatz...
plastics_processed %>%
  #..pivotiert die Plastikarten
  tidyr::pivot_longer(
    cols = c(hdpe, ldpe, o, pet, pp, ps, pvc), # Betroffene Variablen
    names_to = "plastic_type",                 # Zielspalte
    values_to = "n_pieces"                     # Wertspalte
    ) %>%
  # ..und faktorisiert sicherheitshalber die anderen Variablen (nicht immer notwendig)
  dplyr::mutate(dplyr::across( # Zu Faktor konvertieren
    .cols = c(country, continent, year, plastic_type),
    .fns = as_factor
    ))
```

Mit `dyplr::pivot_wider()` könnten wir den Datensatz auch wieder in das breite Format bringen, wobei wir Euch empfehlen, die lange Form zu nutzen.

---

# **Datensätze zusammenfügen**

Häufig ist es auch der Fall, dass mehrere Datensätze zu einem zusammengefügt werden sollen. Im Exkurs "APIs" zwei Session "Datenimport" haben wir bereits mit einem Datensatz der Weltbank zu Naturschutzgebieten (`wb_areas`) gearbeitet. Falls Ihr den Exkurs (noch) nicht angeschaut habt, ist das auch kein Problem! Verschafft Euch zuerst nochmal einen kleinen Überblick über den Datensatz `wb_areas`: 

``` {r 08gdppc, exercise = TRUE}
# Hier Euer Code!

```

``` {r exercise_08gdppc-solution}
# NAs bestimmen
summary(wb_areas)
```

``` {r exercise_08gdppc-check}
grade_this_code()
```

Der Datensatz soll für für die Planung von zukünftigen Aktivitäten und die Kommunikation mit Freiwilligen und Fördernden genutzt werden und ist daher auch für das Netzwerk #Breakfreefromplastics besonders spannend. Der Indikator *ER.PTD.TOTL.ZS* gibt beispielsweise an, wie viel Prozent der Landes- und Wasserfläche aus Naturschutzgebieten besteht.

## **Interkative Übung**

Diesen Datensatz `wb_areas` wollen wir nun mit dem `community`-Datensatz zusammenfügen. Dafür brauchen wir eine **gemeinsame Variable**, die R dafür verwenden kann, um die Länder einander zuzuordnen. Die gemeinsame Variable muss in beiden Datensätzen den **gleichen Namen** haben oder von uns zugeordnet werden. Dabei muss die Kodierung (hier ISO2C) übereinstimmen. Da Ländernamen fehleranfällig sind, fokussieren wir uns auf die **Country Codes**:

``` {r 08wb_clean, exercise = TRUE}
# Umbennung der Spalten
wb_areas %>% 
  dplyr::select(countrycode = 'iso2c', protected_area = 'ER.PTD.TOTL.ZS')
```

Versucht jetzt einmal herauszufinden, wie viele Länder in beiden Datensätzen `community` und `wb_areas` vorhanden sind (hier führen viele Wege zum Ziel!):

``` {r 08_datenbereinigung, exercise = TRUE}
# Hier Euer Code!

```

```{r 08quiz_datenbereinigung5}
quiz(caption = NULL,
  question("Wie viele Länder sind im Datensatz der World Bank enthalten?",
    answer("3"),
    answer("266", correct = TRUE),
    answer("51"),
    answer("4084"),
    correct = "Gut gemacht!",
    incorrect = "Das ist leider nicht ganz richtig. Probiert es nochmal!",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  )
)
```

```{r 08quiz_datenbereinigung6}
quiz(caption = NULL,
  question("Wie viele Länder sind in Community enthalten?",
    answer("51", correct = TRUE),
    answer("4"),
    answer("9296"),
    answer("4084"),
    correct = "Gut gemacht!",
    incorrect = "Das ist leider nicht ganz richtig. Probiert es nochmal!",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  )
)
```

Nun können wir die beiden Datensätze zusammenfügen. Da in dem Datensatz `wb_areas` viel mehr Länder vorkommen, gibt es verschiedene Möglichkeiten:

- `inner_join`: nur die Länder werden beibehalten, die **in beiden Datensätzen** enthalten sind
- `full_join`: **alle Länder** aus beiden Datensätzen sind enthalten
- `left_join`/`right_join`: nur die **Länder aus dem zuerst bzw. zuletzt genannten Datensatz** bleiben enthalten

![](https://d33wubrfki0l68.cloudfront.net/aeab386461820b029b7e7606ccff1286f623bae1/ef0d4/diagrams/join-venn.png){#id .class width=80% height=100%}

Führt die folgenden Codeblöcke nacheinander aus und schaut Euch an, wie diese verschiedenen Joins für Euren Datensatz in der Praxis funktionieren:

``` {r 08inner_join, exercise = TRUE}
# Ihr nehmt Euren ersten Datensatz...
community %>%
  # ...und führt den Join aus
  dplyr::inner_join(wb_processed, by = "countrycode")
```

``` {r 08full_join, exercise = TRUE}
# Ihr nehmt Euren ersten Datensatz...
community %>%
  # ...und führt den Join aus
  dplyr::full_join(wb_processed, by = "countrycode")
```

``` {r 08left_join, exercise = TRUE}
# Ihr nehmt Euren ersten Datensatz...
community %>%
  # ...und führt den Join aus
  dplyr::left_join(wb_processed, by = "countrycode")
```

``` {r 08right_join, exercise = TRUE}
# Ihr nehmt Euren ersten Datensatz...
community %>%
  # ...und führt den Join aus
  dplyr::right_join(wb_processed, by = "countrycode")
```

```{r 08quiz_datenbereinigung8}
quiz(
  caption = NULL,
  question("Wie Ihr sehen könnt, führt der full_join natürlich zu den meisten Zeilen im Datensatz und der inner_join zur geringsten Anzahl an Ländern. Welcher der beiden anderen Joins führt zu einer höheren Anzahl an Ländern im Datensatz?",
    answer("left_join"),
    answer("right_join", correct = TRUE),
    correct = "Gut gemacht!",
    incorrect = "Das ist leider nicht ganz richtig. Probiert es nochmal!",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  question("Welche der folgenden Aussagen sind wahr?",
    answer("Beim Inner Join bleiben nur Zeilen bestehen, die in beiden Datensätzen vorhanden sind (n = 50)", correct = TRUE),
    answer ("Beim Full Join bleiben alle Zeilen bestehen, passende werden zusammengefügt (n = 267)", correct = TRUE),
    answer ("Beim Left Join bleiben alle Zeilen des links referenzierten Datensatzes (community) bestehen, passende werden zusammengefügt (n = 51)", correct = TRUE),
    answer ("Beim Right Join bleiben alle Zeilen des rechts referenzierten Datensatzes (wb_areas) bestehen, passende werden zusammengefügt (n = 266)", correct = TRUE),
    correct = "Gut gemacht!",
    incorrect = "Das ist leider nicht ganz richtig. Probiert es nochmal!",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  )
)
```

---

# **Und jetzt Ihr**
...

---

# **Zusätzliche Ressourcen**
- [Schummelblatt: tidyr](https://github.com/CorrelAid/lernplattform/blob/main/cheatsheets/06_cheatsheet-tidyr.pdf){target="_blank"} (engl.)
- [Data Cleaning in R](https://app.dataquest.io/course/r-data-cleaning){target="_blank"} auf DataQuest (engl.)
- [Advanced Data Cleaning in R](https://app.dataquest.io/course/r-data-cleaning-advanced){target="_blank"} auf DataQuest (engl.)
- ...


<a class="btn btn-primary btn-back-to-main" href=`r params$links$end_session`>Session beenden</a>

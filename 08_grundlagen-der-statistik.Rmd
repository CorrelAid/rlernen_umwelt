---
title: "Grundlagen der Statistik"
author: CorrelAid e.V.
date: "`r Sys.Date()`"
authors:
  - Nina Hauser
  - Zoé Wolter
  - Jonas Lorenz
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    theme: flatly
    css: www/style.css
    includes:
      after_body: ./www/favicon.html
    language: de
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(learnr)
library(gradethis)
library(ggplot2)
 
source("R/setup/gradethis-setup.R")
source("R/setup/tutorial-setup.R")
# Read app parameters
params <- yaml::yaml.load_file("www/app_parameters.yml")

# Benötigte Daten laden
source("R/setup/functions.R")
z <- get_z()
```

```{r results='asis'}
cat(get_license_note(rmarkdown::metadata$title, rmarkdown::metadata$authors))
```

![*Video: Grundlagen der Statistik (30min)*](https://youtu.be/ASL2IihMtl0)

<p style="border-width:1px; border-style:solid; border-color:#acc940; padding: 1em;">
  **Disclaimer** <br>
  Du hast alles direkt verstanden? Perfekt!
  Du hast nicht alles direkt verstanden? Völlig normal! Nimm Deine Fragen gerne mit in die Livesession - die Tutor:innen freuen sich darüber, alle Deine Fragen zu beantworten und Dir weiterzuhelfen. Bei kleineren Fragen wende Dich natürlich auch gerne einfach direkt an Deine:n Mentor:in. Und wenn Du gar nicht weißt, wo Du anfangen sollst mit Deinen Fragen - ein kleiner Schritt nach dem anderen und nicht alles brauchst Du für jede Datenanalyse oder -visualisierung. 
</p>

Nachdem wir uns in der vergangenen Woche mit den juristischen und ethischen Hintergründen der Datenverarbeitung beschäftigt haben, werden wir uns in diesem Kapitel den **Grundlagen des statistischen Denkens** widmen.
Wir beschäftigen uns aber nicht aus purem Selbstzweck mit der Statistik. Vielmehr sind die statistischen Überlegungen und Konzepte ein ganz wesentlicher Teil und **Grundvoraussetzung** für den kritischen Umgang mit Daten. Daher schauen wir uns zu Beginn an, was wir für einen kompetenten Umgang mit Daten benötigen, wie wir die notwendige **Datenkompetenz** erlangen können und welche Rolle die Statistik dabei spielt. Wir beginnen anschließend mit einer Einführung in die Statistik und werfen einen Blick darauf, wie **Daten in der Öffentlichkeit** präsentiert werden. 
Außerdem lernen wir, was man unter dem Begriff "Daten" versteht und welche **Datentypen** es eigentlich gibt. Mit unserem neu erlangten Wissen schauen wir uns an, wie Daten (mehr oder weniger) sinnvoll zusammengefasst werden können. Abschließend diskutieren wir das wichtige Thema **Korrelation und Kausalität** und werden verstehen, was sich hinter diesen Begriffen verbirgt.
Los geht's!

# **Data Literacy**

Im digitalen Zeitalter ist der **kometente Umgang mit Daten** eine Schlüsselqualifikation für gesellschaftliche Teilhabe, Wohlstand und Wettbewerbsfähigkeit, den Schutz von Klima und Umwelt sowie staatliches Handeln. Die **Fähigkeiten, Daten auf kritische Art und Weise zu sammeln, zu verwalten, zu bewerten und anzuwenden, wird als Data Literacy bezeichnet**. Dieser Begriff umfasst dabei nicht nur Statistikkompetenz oder ein mathematisches Grundverständnis, sondern auch Fertigkeiten wie Digital- und Medienkompetenz. Wer datenkompetent („data literate“) ist, kann die Zuverlässigkeit von Datenquellen beurteilen, Daten zielgerichtet aufbereiten und einordnen sowie sinnvolle Schlüsse aus diesen Daten ziehen.

Wenn Daten Entscheidungsprozesse unterstützen sollen, braucht es kompetente Antworten auf vier grundlegende Fragen:
  - Was will ich mit Daten machen? Daten und Datenanalysen sind kein Selbstzweck, sondern dienen einer konkreten Anwendung in der realen Welt.
  - Was kann ich mit Daten machen? Datenquellen und deren Qualität sowie der Stand der technischen und methodischen Entwicklungen eröffnen  Möglichkeiten und setzen Grenzen.
  - Was darf ich mit Daten machen? Alle gesetzlichen Regeln der Datennutzung (zum Beispiel Datenschutz, Urheberrechte und Lizenzfragen) müssen immer mitbedacht werden.
  - Was soll ich mit Daten machen? Weil Daten eine wertvolle Ressource darstellen, leitet sich daraus ein normativer Anspruch ab, sie zum Wohl von Individuen und Gesellschaft zu nutzen.

In der nachfolgende Abbildung zeigt ein zyklisches Prozessmodell die notwendigen Schritte für einen kompetenten Umgang mit Daten. Weil der gesamte Prozess mehrfach durchlaufen werden kann, vermittelt das Schaubild keinen klaren Startpunkt. Gewöhnlich beginnt man jedoch mit der Eingrenzung der Aufgabe und der Formulierung von (Forschungs-)Fragen.

<p>
<center>
![**Abbildung**: Zyklisches Modell des Prozesses der Wertschöpfung aus Daten. Quelle: Schüller, Busch, Hindinger (2019)](https://github.com/CorrelAid/lernplattform/blob/main/abbildungen/08_grundlagen-der-statistik/Zyklisches_Modell.png?raw=true){#id .class width=70% height=70%}
</center>
</p>

Die Statistik ist dabei an fast allen Schritten beteiligt:
  - Planung der Datenerhebung (Messung): Statistische Überlegungen entscheiden darüber, welche Daten in welchen Einheiten erhoben werden sollen.
  - Durchführung der Datenerhebung: Das Wissen über statistische Verteilungen bestimmter Merkmale innerhalb einer Gesellschaft (z.B. Altersverteilungen, etc.) ist bei der Auswahl der Stichprobe von großer Bedeutung und hilft, Messfehler und Verzerrungen zu vermeiden bzw. zu minimieren.
  - Datenanalyse: Statistischer Berechnungen helfen dabei, Muster und Auffälligkeiten in den Daten zu finden.
  - Interpretation der Daten: Mithilfe statistischer Modelle können gefundene Zusammenhänge überprüft und bewertet werden.
  - Entscheidungsfindung: Mithilfe der statistischen Bewertungen können auf Basis der erhobenen Daten wissenschaftlich fundierte Entscheidungen getroffen werden.

Wie wir sehen, ist eine grundlegende Datenkompetenz also von enormer Bedeutung. Deshalb wollen wir uns näher mit den Grundlagen der Statistik beschäftigen und tun dies so praxisnah und anwendungsorientiert wie möglich zu gestalten, indem wir uns auf die Grundlagen fokussieren, die Ihr beim Umgang mit Euren eigenen Daten und Datensätzen direkt angewenden könnt!

# **Einführung in die Statistik**

Die Statistik ist eine Wissenschaft, die alle Lebensbereiche durchdringt. Wir alle sind täglich einer Fülle von Daten und Visualisierungen von Daten ausgesetzt, die uns über die verschiedene Kanäle erreichen. Im Internet kann man gezielt nach Daten aller Art suchen, z.B. nach statistischen Informationen zu Migrationsströmen oder zur Kursentwicklung von Kryptowährungen. Zugleich wird die Online-Präsentation von Daten immer benutzerfreundlicher. Dies gilt insbesondere für Daten der amtlichen Statistik – wie das folgende Beispiel einer [interaktiven Präsentation der Bevölkerungsvorausberechnung](https://service.destatis.de/bevoelkerungspyramide/){target="_blank"} für Deutschland des Statistischen Bundesamts (Destatis) zeigt.

![**Video:** von6auf1 - "Statistische Daten - Merkmalsträger, Merkmalsausprägung ..." (3min)](https://youtu.be/fmpxGo1JJiE?si=5_Wu79t3LVA9gmLF)(04.11.2015, abgerufen August 2024)

In der Statistik nennt man die Objekte, auf die sich eine statistische Untersuchung bezieht, **statistische Einheiten oder Merkmalsträger:innen**. An diesen Merkmalsträger:innen werden die Daten also erhoben. Die Menge aller (zur Beantwortung einer Fragestellung relavanten) Merkmalsträger:innen bildet eine **Grundgesamtheit (auch: Population)**. Diese muss klar definiert und als solche von anderen Personengruppen abgegrenzt sein. Als **Merkmale (auch: Variablen)** werden dabei die Eigenschaften der Merkmalsträger:innen bezeichnet. Unter dem Begriff der **Merkmalsausprägungen** werden dabei alle möglichen Werte gefasst, die ein Merkmal annehmen kann. Da sich in der Realität selten alle Personen der Grundgesamtheit erreichen lassen, wählt man nach einem **Auswahlverfahren (engl. Sampling)** eine Teilmenge aus, die sogenannte **Stichprobe**.

<div style="border-width:1px; border-style:solid; border-color:#acc940; padding: 1em;">
<p style="color:#acc940;"><b>Beispiele:  Statistische Grundbegriffe</b></p>

Eine Grundgesamtheit ist z.B. definiert durch

- alle Personen, die am 1. Mai 2023 in Berlin ihren Erstwohnsitz hatten;
- Studierende einer Universität zu Beginn des Wintersemesters 2023, über die man via Internetbefragung Informationen gewinnen will;

Die statistischen Einheiten werden hier repräsentiert durch

- jede Person mit Erstwohnsitz in Berlin am 1. Mai 2023;
- alle zum Wintersemester 2023 eingeschriebenen Studierenden;

Interessierende Merkmale und Merkmalsausprägungen können hier sein

- der Familienstand der Person, etwa mit den Ausprägung „single“, "verheiratet", "geschieden"; 
- das Alter der Studierenden, erfasst z.B. in Form von Altersklassen;
</div>

Die folgende Abbildung verdeutlicht noch einmal den Zusammenhang zwischen Population und Stichprobe.

<p>
<center>
![**Abbildung**: Population und Stichprobe. Quelle: <https://systats.github.io/linear_model/basics.html>](https://systats.github.io/linear_model/images/pop/population.png){#id .class width=70% height=70%}
</center>
</p>

## **Aufgaben und Teilbereiche der Statistik**

Für Statistiker:innen ist der Begriff „Statistik“ nicht eindeutig definiert. Einerseits verstehen sie darunter ihre **Wissenschaft als Ganzes**, andererseits verwenden sie den Begriff aber auch für sogenannte **statistische Kenngrößen**, die sich aus den Daten ableiten (z.B. den Mittelwert). Wir verstehen im Rahmen dieses Kurses **„Statistik“ im Sinne von „Wissenschaft“**, die sich mit der Sammlung, Analyse, Interpretation, Präsentation und Organisation von Daten befasst. Die damit verbundenen Methoden und Werkzeuge nutzen wir, um große Mengen an Informationen systematisch zu untersuchen und daraus nützliche Erkenntnisse zu gewinnen.

Innerhalb der Statistik lassen sich die beschreibende und die schließende Statistik unterscheiden. 
Die **beschreibende (auch: deskriptive) Statistik** umfasst numerische und grafische Verfahren zur Charakterisierung und Präsentation von Daten. 
  - Ziel: Zusammenfassung der, in den Daten enthaltenen, statistischen Informationen.
  - Methoden: Reduktion zu wenigen Kenngrößen, bei möglichst minimalem Informationsverlust. 

Aus der beschreibenden Statistik hat sich die **explorative Datenanalyse** entwickelt, die noch ohne Einsatz von (mathematischen) Modellen, sondern auf Basis rechenintensiver Verfahren nach auffälligen Mustern und Strukturen in Datenbeständen sucht.
  - Bsp.: Routinemäßige Kontroll der täglichen Scannerdaten eines Lebensmittelkonzerns nach Auffälligkeiten ohne konkrete Hypothese.
  - Ziel: Entdeckung von Trends im Kaufverhalten der Kund:innen und rechtzeitige Organisation der Bestellungen.

Die **schließende (auch: induktive) Statistik** leitet aus Stichprobendaten Aussagen ab, die über die jeweilige Stichprobe hinausgehen und sich auf eine umfassendere Grundgesamtheit beziehen. Sie sei aber nur der Vollständigkeit halber genannt und wird uns heute nicht weiter beschäftigen. Für diesen Kurs wollen wir uns nämlich in erster Linie auf den Zweig der **beschreibenden Statistik** konzentrieren. Um einen ersten Einblick in die Arbeit von Statistiker:innen zu bekommen, wollen wir einige Pressemitteilungen des Statistischen Bundesamts (Destatis) näher ansehen. Diese Pressemitteilungen sind typische Beispiele für die Veröffentlichungen von statistischen Ämtern und zeigen, wie Daten in der Öffentlichkeit präsentiert werden.
Achtet auf die Kommunikation sowie die verschiedenen Darstellungsarten. Welches Wissen bzw. welche Fähigkeiten werden bei den Betrachter:innen vorausgesetzt? Welche Informationen werden vermittelt? Findet ihr die Grafiken geeignet, um die Informationen zu vermitteln?

### **Pressemitteilungen**

-> drei umweltbezogene Pressemitteilungen inkl. Fragen

# **Was sind Daten?**

Nachdem wir uns mithilfe der Pressemitteilungen bereits ein erstes Mal mit Daten und Datenvisualisierungen auseinandergesetzt haben, ist es nun an der Zeit, dass wir einmal genau festlegen, was wir mit Daten eigentlich meinen. Was also sind eigentlich Informationen und Daten?

Eine **Information** ist abgeleitetes Wissen, welches wir Anderen vermitteln und aufbewahren wollen. Die können wir unter anderem durch die Wahl einer geeigneten **Kodierung** erreichen. Diese kodierten Informationen bezeichnen wir wiederum als **Daten**. Da ein und dieselbe Information auf unterschiedliche Art und Weise kodiert werden kann (verschiedene Einheiten, verschiedene Skalen usw.), kann ein und dieselbe Information auch mit unterschiedlichen Daten ausgedrückt werden. Allerdings müssen wir darauf achten, dass wir die Kodierung so verständlich wie möglich gestalten - denn was bringen uns die Daten, wenn wir die darin enthaltenen Informationen nicht verwerten können?

Stellen wir uns einmal eine gewöhnliche Tabelle vor, so enthält diese kodierte Informationen und somit Daten. Eine solche Tabelle mit Daten nennen wir daher auch einen **Datensatz**.
Jede Zeile einer Tabelle bildet eine zusammenhängende **Informationseinheit**, die zu einem bestimmten Zeitpunkt erhoben oder gemessen wurde. Deshalb bezeichnen wir die Zeilen als *Messungen, Beobachtungen, Aufzeichnungen (engl. records), oder Versuche*.

Jede Spalte einer Tabelle repräsentiert eine **Eigenschaft**, die uns interessiert, und die für alle Zeilen auf die gleiche Art und Weise kodiert wird, so dass wir die verschiedenen Messungen leicht vergleichen können. Daher bezeichnen wir die Spalten als *Merkmale, Features, Attribute, Felder, oder Variablen*. Einen Datensatz kann mal also auch beschreiben als eine Sammlung von *N* Beobachtungen mit *Y* Merkmalen oder Variablen. Man spricht in diesem Falle von der **Dimension (auch: Komplexität)** des Datensatzes. 

Ein **Datenpunkt (auch: Datenwert)** ist der Schnittpunkt (= eine Zelle in der Tabelle) zwischen einer Beobachtung und einem Merkmal. Jede Tabelle besitzt eine Kopfzeile (engl. header), die die Merkmale näher beschreibt.

Die nachfolgende Abbildung stellt alle Begriffe dieses Abschnittes noch einmal übersichtlich zusammen.

<p>
<center>
![**Abbildung**: Grundbegriffe für den Umgang mit tabellarischen Datensätzen. Quelle: Eigene Darstellung.](https://github.com/CorrelAid/lernplattform/blob/main/abbildungen/08_grundlagen-der-statistik/Datensatz.png?raw=true){#id .class width=100%}
</center>
</p>

```{r 08_quiz_datensatz, echo=FALSE}
quiz(caption = "Fragen zu tabellarischen Daten",
  question("Wie viele Merkmale hat der Datensatz aus der Abbildung?",
    answer("2"),
    answer("3", correct = TRUE),
    answer("4"),
    answer("5"),
    correct = "Richtig. Der Datensatz hat 3 Merkmale: 'Name', 'Alter' und 'Reaktionszeit'. 'Index' ist kein Merkmal im eigentlichen Sinne, da es automatisch für uns erzeugt wird.",
    incorrect = "Leider falsch. Zähle nochmal die Spalten in der Tabelle. Ist 'Index' ein Merkmal, dass wir messen würden?",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    ),
  
  question("Wie viele Beobachtungen hat der Datensatz aus der Abbildung?",
    answer("2"),
    answer("3"),
    answer("4", correct = TRUE),
    answer("5"),
    correct = "Richtig. Der Datensatz zeigt vier Beobachtungen, da es vier Zeilen mit befüllten Werten gibt und jede Zeile ist eine Beobachtung/Messung.",
    incorrect = "Leider falsch. Zähle nochmal die Zeilen in der Tabelle.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    ),
  
  question("Wie lauten die Dimensionen des Datensatzes aus der Abbildung?",
    answer("4x4"),
    answer("4x3", correct = TRUE),
    answer("3x4"),
    answer("3x3"),
    correct = sprintf("Richtig. Die Dimension eines Datensatzes wird angegeben als Anzahl Zeilen $\\times$ Anzahl Spalten, daher ist die richtige Antwort $4 \\times 3$"),
    incorrect = "Leider falsch. Die Dimension eines Datensatzes wird angegeben als Anzahl Zeilen $\\times$ Anzahl Spalten.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    )
)
```

## **Datentypen**

Je nach Kodierung der Daten unterscheiden wir verschiedene Datentypen. **Numerische** und **kategorische** Daten bilden dabei die beiden wichtigsten Datentypen. Auf der einen Seite werden Daten in Form von Zahlen (und ggf. Einheiten) ausgedrückt - man spricht dann von numerischen Daten. Diese können wiederum in zwei Hauptkategorien unterteilt werden: 

  - **Kontinuierliche Daten** können jede Zahl innerhalb eines bestimmten Bereichs annehmen, wodurch sie eine grundsätzlich nicht zählbare Menge von Werten darstellen. Das heißt, dass es immer noch einen Wert zwischen zwei beliebigen Werten gibt. 
Beispiele für diesen Datentyp sind Wetterdaten wie die Menge an Niederschlag oder die Außentemperatur. Die Außentemperatur kann beispielsweise mit beliebiger Genauigkeit angegeben werden: 29 °C, 28,6 °C, oder 28,6425 °C.
  - **Diskrete Daten** sind im Gegensatz dazu auf ganze Zahlen beschränkt, womit sie eine abzählbare Menge von Werten darstellen. 
Beispiele für diesen Datentyp sind die Anzahl der Kinder in einer Familie oder die Anzahl der Tore in einem Fußballspiel. Man kann 0,1,2 oder mehr Kinder haben, aber nicht 1,28 Kinder.

-> Grafik: Numerische Datentypen.

Auf der anderen Seite gibt es Daten, die mithilfe von Worten und Symbolen ausgedrückt werden - die sogenannten kategorischen Daten. Allerdings gibt es auch kategorische Daten, die trotz ihres numerischen Charakters nur sinnvoll als kategorische Daten interpretiert werden können (z.B. Postleitzahlen).
Wie die numerischen Daten, können auch die kategorischen Daten in zwei Hauptkategorien unterteilt werden:

  - **Ordinale Daten** sind Daten bei denen die Werte eine natürliche Reihenfolge haben, aber die Abstände zwischen den Werten nicht notwendigerweise gleich sind. Ein Beispiel wären Schulnoten, bei denen die Note 1 besser ist als die Note 2, aber der Unterschied zwischen den beiden Noten nicht genau quantifizierbar ist. Diese Daten erlauben Vergleiche wie größer/kleiner, aber keine präzisen Berechnungen von Differenzen. Umfragen nutzen Ordinaldaten, wenn sie nach eurer Erfahrung oder Zustimmung auf einer Skala von 1-10 fragen. Die Werte sehen zwar wie diskrete Daten aus, aber es ist nicht möglich oder sinnvoll, den Abstand zwischen zwei Werten zu interpretieren - man kann schließlich nicht sagen, dass ob Abstand zwischen einer 9 und 10 in einer Umfrage identisch ist mit dem Abstand zwischen einer 0 und einer 1. Ordinaldaten müssen allerdings auch nicht mit Zahlen kodiert sein (s. Kleidergrößen: S, M, L, ...).
  - **Nominale Daten** sind qualitative Daten, die in Kategorien eingeteilt werden, ohne dass eine natürliche Reihenfolge zwischen den Kategorien besteht. Ein Beispiel sind Farben (z.B. Rot, Blau, Grün) oder Geschlechter (männlich, weiblich), bei denen keine Rangfolge oder Vergleichbarkeit hinsichtlich größer oder kleiner besteht. Nominale Daten dienen der Klassifizierung, aber arithmetische Operationen sind nicht sinnvoll.

-> Grafik: Kategorische Datentypen.

## **Skalenniveaus**

Die Unterscheidung der Datentypen wird mithilfe sogenannter **Skalenniveaus** vorgenommen. Warum sind diese sogenannten Skalenniveaus wichtig für uns? 
Das Skalenniveau unserer Daten **bestimmt, welche statistischen Methoden angewendet werden können**. So können beispielsweise Mittelwerte nur für kontinuierliche numerische Daten sinnvoll berechnet werden (man denke an den Notenspiegel aus der Schule, bei dem die Durchschnittsnote wenig sinnvoll ist, wenn Noten selbst diskrete Werte darstellen). Nominale kategorische Daten hingegen lassen sich nur sinnvoll über Häufigkeiten zusammenfassen, mehr kann man mit ihnen nicht anstellen.

```{r 08_quiz_datentypen, echo=FALSE}
quiz(caption = "Fragen zu Datentypen",
  question("Welches Merkmal hat einen kategorischen Datentyp im Datensatz aus der Abbildung?",
    answer("Name", correct = TRUE),
    answer("Alter"),
    answer("Reaktionszeit"),
    correct = "Richtig. Das Merkmal 'Name' enthält Text und ist daher eine klassische (nominale) kategorische Variable.",
    incorrect = "Leider falsch. Kategorische Daten sind oftmals als Text oder Symbole kodiert.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    ),
  
  question("Welches Merkmal hat einen diskreten numerischen Datentyp im Datensatz aus der Abbildung?",
    answer("Name"),
    answer("Alter", correct = TRUE),
    answer("Reaktionszeit"),
    correct = "Richtig. Das Merkmal 'Alter' ist klassischerweise eine diskrete numerische Variable, weil wir das Alter für gewöhnlich in ganzen Jahren (oder Tage/Monaten) angeben.",
    incorrect = "Leider falsch. Diskrete numerische Daten sind als ganze Zahlen kodiert.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    ),
  
  question("Welches Merkmal hat einen kontinuierlichen numerischen Datentyp im Datensatz aus der Abbildung?",
    answer("Name"),
    answer("Alter"),
    answer("Reaktionszeit", correct=TRUE),
    correct = "Richtig. Das Merkmal 'Reaktionszeit' wird in Sekunden gemessen und kann daher jeden beliebigen Wert annehmen und ist letztendlich nur durch die Genauigkeit der Messung begrenzt.",
    incorrect = "Leider falsch. Kontinuierliche numerische Daten sind oftmals mit Kommazahlen kodiert.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  )
)
```

Jetzt, wo wir uns mit den Grundlagen von Daten auskennen, können wir zur eigentlichen Statistik kommen.

# **Einführung in die deskriptive Statistik**<sup><a href="#section-quelle-3">3</a></sub>

Die **Herausarbeitung wesentlicher Charakteristika von Häufigkeitsverteilungen** ist ein grundlegendes Ziel der deskriptiven Statistik (acuh: beschreibende Statistik). Dies geschieht in der Regel mithilfe von **Kennzahlen und grafischen Darstellungen**, die Ihr in einer späteren Lektion kennenlernen werdet. Eine Häufigkeitsverteilung ist eine Zusammenfassung der beobachteten Werte einer Variable und gibt an, wie oft die verschiedenen Werte vorkommen. Die Häufigkeit kann dabei pro Merkmalsausprägung oder für Klassen angegeben werden, die mehrere Merkmalsausprägungen zusammenfassen (z.B. Alters- und Einkommensgruppen).

## **Lageparameter**

Mithilfe von Lageparametern kann man die Frage beantowrten, welche der (in der Stichprobe vorkommenden) Werte “typisch” oder “repräsentativ” sind. Aber Vorsicht: Ihr solltet diese Werte nicht überinterpretieren, schließlich reduzieren sie den gesamten Datensatz auf eine einzige Zahl.

**Modus (auch: Modelwert):** Enspricht dem häufigsten Wert, den eine bestimmte Variable annimmt. Hierzu ermittelt man die häufigste (oder wahrscheinlichste) Beobachtung.

**Median:** Entspricht dem “wahren” Mittelpunkt einer Variable (50 % aller Beobachtungen sind kleiner und 50 % aller Beobachtungen sind größer als der Median). Hierzu ordnet man man alle Beobachtungen in aufsteigender Reihenfolge und bestimmt, welche Beobachtung genau in der Mitte liegt.

**Arithmetisches Mittel:** Enspricht dem Durchschnittswert einer Variable. Hierzu addiert man alle Einzelbeobachtungen und teilt anschließend durch die Anzahl der Beobachtungen.

Dass ein und dieselbe Verteilung (beispielsweise die Erhebung des Einkommens einer Stichprobe) ganz unterschiedliche Lagemaße haben kann, zeigt die folgende Abbildung.

<p>
<center>
![**Abbildung**: Schiefe vs. symmetrische Verteilungen. Quelle: Eigene Darstellung](https://github.com/CorrelAid/lernplattform/blob/main/abbildungen/08_grundlagen-der-statistik/Schiefe_Verteilungen.png?raw=true){#id .class width=100%}
</center>
</p>

```{r 08_quiz4, echo=FALSE}
quiz(caption = "Frage zu Lageparametern",
  question(sprintf("Gegeben sei die folgende Variable metrischen Messniveaus mit folgenden Ausprägungen: $x = [0, 1, 2, 4, 3, 1, 2]$. Wie lautet der Modus?"),
    answer("0",),
    answer("1", correct = TRUE),
    answer("2", correct = TRUE),
    answer("3"),
    answer("4"),
    correct = "Richtig! Diese Variable besitzt zwei häufigste Werte, 1 und 2.",
    incorrect = "Leider falsch. Der Modus ist der häufigste Wert. Der Modus kann dabei auch mehrere Zahlen umfassen.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    ),
  
  question(sprintf("Gegeben sei die folgende Variable metrischen Messniveaus mit folgenden Ausprägungen: $x = [0, 1, 2, 4, 3, 1, 2]$. Wie lautet der Median?"),
    answer("0",),
    answer("1"),
    answer("2", correct = TRUE),
    answer("3"),
    answer("4"),
    correct = "Richtig! Der Median lautet 2. Wenn wir die Werte sortieren, erhalten wir die Reihenfolge 0, 1, 1, 2, 2, 3, 4. Wir haben 7 Messwerte und der mittlere Wert ist der Wert an der Stelle 4, also der Messwert 2.",
    incorrect = "Leider falsch. Der Median ist der mittlere Wert der geordneten Messreihe.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    ),
  
  question(sprintf("Gegeben sei die folgende Variable metrischen Messniveaus mit folgenden Ausprägungen: $x = [0, 1, 2, 4, 3, 1, 2]$. Wie lautet der Mittelwert?"),
    answer("0",),
    answer("1"),
    answer("2"),
    answer("3"),
    answer("4"),
    answer("1,86", correct = TRUE),
    correct = sprintf("Richtig! Der Mittelwert lautet 1,86. Dazu müssen zuerst alle Werte aufaddiert werden (=13), um anschließend durch die Anzahl der Messwerte (=7) geteilt zu werden. Wie wir sehen, ist der Mittelwert kein Wert, der in der Messung selber vorkommt, sondern ein fiktiver Wert."),
    incorrect = "Leider falsch. Der Mittelwert ist die Summe aller Messwerte, geteilt durch die Anzahl der Messwerte.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    ),
  
  question("Warum sind schiefe Verteilungen problematisch?",
    answer("Eine Idee", correct = TRUE),
    answer("Keine Idee"),
    correct = "Schiefe Verteilungen sind problematisch, weil viele statistische Modelle und Berechnungen von einer symmetrischen Verteilung ausgehen, insbesondere davon, dass die Werte gleichmäßig um den Mittelwert herum verteilt sind. Ist eine Verteilung besonders 'schief', so hat sie entweder einen langen Schwanz (engl. tail) auf der linken oder rechten Seite, d.h., ganz viele Werte mit besonders kleinen oder großen Werten. Alleine schon der Mittelwert ist für solche Verteilungen problematisch, weil er nicht mehr wirklich repräsentativ ist (siehe Abbildung). Er befindet sich viel näher an den wenigen Extremwerten als am Großteil der Werte. Mithilfe von Transformationen kann man manchmal eine solche Verteilung wieder 'normalisieren', z.B. mithilfe des Logarithmus'.",
    incorrect = "Macht nichts, einfach die andere Option wählen ;). Stell dir eine Gehaltsverteilung wie die obige in der Grafik vor: Welchen Wert würdest du für das durchschnittliche Gehalt nennen? Den Mittelwert oder den Median? Warum?",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    )
)
```

## **Streuungsparameter** 

Streuungsparameter beschreiben das Ausmaß der **Streuung der Daten** innerhalb des Datensatzes oder um einen Lageparameter herum. So gibt beispielsweise die Standardabweichung einer Variable an, wie weit im Mittel die einzelnen Beobachtungen vom Mittelwert dieser Variable entfernt sind.

**Standardabweichung (auch: mittlere Abweichung)**: Ein standardisiertes Maß für die Streuung der einzelnen Beobachtungen vom Mittelwert einer Variable. Angabe in der selben Maßeinheit wie die Variable.

**Varianz**: Entspricht der quadrierten Standdardabweichung.

**Spannweite (auch: Range)**: Entspricht der Differenz zwischen dem kleinsten Wert (**Minimum**) und dem größten Wert (**Maximumg**) einer Variable.

**p-Quantil**: Entspricht dem Wert, für den mindestens $p\cdot 100 \%$ der Beobachtungen kleiner oder gleich diesem Wert sind. Das 25%-Quantil ($p=25$) ist also der Wert, für den 25 % aller beobachteten Werte kleiner oder gleich diesem Wert sind.

**Interquartilsabstand (IQR)**: Entspricht dem Abstand zwischen dem 75%-Quantil und dem 25%-Quantil und kennzeichnet dementsprechend den Wertebereich, in dem die mittleren 50 % der beobachteten Daten liegen.

In der nachfolgenden Abbildung wird verdeutlicht, wie der Median sowie das 25%-Quantil und 75%-Quantil für eine beispielhafte Messreihe ermittelt werden können.

<p>
<center>
![**Abbildung**: Bestimmung und Bedeutung von p-Quantilen. Quelle: Eigene Darstellung](https://github.com/CorrelAid/lernplattform/blob/main/abbildungen/08_grundlagen-der-statistik/Quantile.png?raw=true){#id .class width=100%}
</center>
</p>

```{r 08_quiz05, echo=FALSE}
quiz(caption = "Frage zu Streuungsparameter",
  question(sprintf("Gegeben sei die folgende Variable metrischen Messniveaus mit folgenden Ausprägungen: $x = [0, 1, 2, 4, 3, 1, 2]$. Wie lautet die Spannweite?"),
    answer("0",),
    answer("1"),
    answer("2"),
    answer("3"),
    answer("4", correct = TRUE),
    correct = sprintf("Richtig! Der größte Wert ist 4, der kleinste Wert ist 0, daher beträgt die Spannweite $4-0=4$."),
    incorrect = "Leider falsch. Die Spannweite ist der Abstand zwischen dem größten und kleinsten Messweret.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    ),
  
  question("Entspricht ein größerer IQR auch einer größeren Streuung/Varianz um den Median?",
    answer("Ja", correct = TRUE),
    answer("Nein"),
    correct = "Richtig! Für den Mittelwert wäre die Sache nicht ganz so einfach, aber der Median liegt IMMER innerhalb des oberen und unteren Quartils (per Definition), daher bedeutet ein größerer IQR auch, dass die Werte (wenigstens am Rand) weiter vom Median entfert sind als bei einem kleineren IQR. Am Boxplot wird dies in einer späteren Lektion am besten ersichtlich.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    ),
  
  question("Kann der Median durch Ausreißer (besonders große oder kleine Werte) verzerrt/beeinflusst werden?",
    answer("Ja"),
    answer("Nein", correct = TRUE),
    correct = "Richtig! Der Median ergibt sich ja durch den mittleren Wert der geordneten Messreihe, d.h., zuerst werden alle Messwerte sortiert und dann wird der Wert in der Mitte herausgezogen. Dieser verändert sich nicht, wenn die Werte am Anfang der Reihe, oder am Ende, noch weiter ins Extreme verschoben werden. Daher sagt man auch, dass der Median ein robustes Lagemaß ist, da er gegenüber Ausreißern unempfindlich ist. Ganz anders als der Mittelwert, bei dem ja alle Werte durch die Aufsummierung in die Berechnung mit einfließen.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    )
)
```

## **Korrelation und Kausalität**

Es gibt eine weitere statistische Größe, die uns wertvolle Aussagen zu den Daten liefern kann, die aber oftmals voreilig als Ursache einer Beziehung interpretiert wird: die Korrelation. Die **Korrelation** ist ein Maß für den Zusammenhang zwischen zwei Variablen. Die häufigste Art der Korrelation nach **Pearson** misst einen **linearen Zusammenhang** (denke an eine gerade Linie durch die Datenpunkte) zwischen zwei Variablen und kann Werte zwischen $-1$ und $1$ annehmen. 

Bei einer **positiven Korrelation** (Werte nahe $+1$) beobachten wir bei Zunahme einer Variable auch eine gewisse Zunahme in der anderen Variable (Bsp.: größere Häuser erzielen für gewöhnlich einen höheren Verkaufspreis). Bei einer **negativen Korrelation** (Werte nahe $-1$) beobachten wir bei Zunahme einer Variable eine Abnahme in der anderen (Bsp.: schwerere Autos besitzen in der Regel einen höheren Kraftstoffverbrauch und somit eine geringere Reichweite). Bei einer Korrelation nahe $0$ können wir **keinen linearen Zusammenhang** erkennen: Unabhängig unseres Wissens über die eine Variable, können wir keine Vorhersage über die Werte der andere Variable treffen.

Die Korrelation kann zur Interpretation der Daten sehr hilfreich, aber auch sehr trügerisch sein. Die **erste wichtige Grundregel** in Bezug auf Korrelationen ist, dass es **verschiedene Korrelationsmaße** gibt. Einige messen nur einen linearen Zusammenhang (d.h. die Daten müssen mehr oder weniger gut auf einer geraden Linie liegen), andere (Rangkorrelationen) können auch nicht lineare Zusammenhänge erfassen. Das ist wichtig, weil eine Korrelation nahe 0 **nicht** bedeutet, dass kein keinen Zusammenhang vorliegt, sondern oft nur, dass der **Zusammenhang eben nicht linear** ist. Man denke an den Zusammenhang zwischen Alter und der aufgenommenen Nahrungsmenge: Mit zunehmendem Alter steigt für gewöhnlich die Menge an Nahrung, die wir zu uns nehmen, an, bis sie ab einem gewissen Alter wieder zu sinken beginnt, weil der Körper nicht mehr so viel Energie benötigt. 

Die **zweite wichtige Grundregel** lautet: **"Aus Korrelation folgt keine Kausalität"**. Zwei Variablen können sogar sehr stark miteinander korrelieren, ohne dass die eine die andere verursacht oder hervorruft. 
  - **Beispiel 1:** Der Verkauf von Eis und die Anzahl der Haiangriffe im Sommer korreliert stark miteinander. Das bedeutet aber nicht, dass der Verkauf von Eis Haie anlockt, oder dass Opfer von Haiangriffen danach gerne ein Eis essen. Vielmehr gibt es eine sogenannte **Drittvariable**, die beide beeinflusst: die Temperatur. Je wärmer es ist, desto mehr Eis wird verkauft und desto mehr Menschen gehen schwimmen. 
  - **Beispiel 2:** Die Schuhgröße korreliert positiv mit der Lesefähigkeit, aber größere Schuhe machen niemanden klüger. In Wahrheit sind beide über das Alter miteinander verbunden. Beim Alter spricht man daher auch von einer **konfundierenden Variable**. 
Außerdem kann man auch rein [zufällige Korrelationen](https://tylervigen.com/spurious-correlations) finden, die absolut keine sinnvolle Erklärung haben dürften (oder hat unser Käsekonsum vielleicht doch eine Ausrikung auf den Aktienmarkt...?).

# **Und jetzt Ihr!**

Zum Abschluss dieser Lerneinheit dürft ihr nun auch noch einmal Daten interpretieren. Schaut euch dazu bitte die folgende Grafik zu [Militärausgaben im Ländervergleich 2003 - 2017](https://www.hfh-fernstudium.de/statistik-app/daten/militaer.html) an:

-> Umweltbezug!

Die zweite Übung behandelt noch einmal die Korrelation. Öffnet dazu bitte diese [Seite](https://www.hfh-fernstudium.de/statistik-app/korrelation.html):

- Erzeugt Beispiele für eine hohe positive Korrelation ($r > +0.8$) und eine hohe negative Korrelation ($r < -0.8$).
- Wenn ihr ein Beispiel für eine hohe Korrelation erzeugt habt, wechselt auf 'Punkte verschieben' und verändert einen Datenpunkt. Wie ändert sich die Korrelation $r$? Warum?
- Erzeugt Beispiele für eine schwache Korrelation ($|r| < 0.2$).
- Erzeugt nun ein Beispiel für einen Zusammenhang, der mit dem Auge sichtbar ist, aber dennoch laut Berechnung ($r$-Wert) keine oder nur eine geringe Korrelation aufweist. Woran liegt das?

# **Quellen**

- <span id="quelle-1">[1]</span> Data-Literacy-Charta. (n.d.). Stifterverband.org. Retrieved February 14, 2024, from <https://www.stifterverband.org/charta-data-literacy>.
- <span id="quelle-2">[2]</span> Mittag, H.-J., & Schüller, K. (2020). Statistik: Eine Einführung mit interaktiven Elementen. Springer Berlin Heidelberg.
- <span id="quelle-3">[3]</span> Gutman, A. J., & Goldmeier, J. (2022). Werde ein Data Head: Data Science, Machine Learning und Statistik verstehen und datenintensive Jobs meistern.


# **Zusätzliche Ressourcen**

- [Destatis - Statistisches Bundesamt](https://www.destatis.de/DE/Home/_inhalt.html)
- [KI Campus](https://ki-campus.org/)
- [https://systats.github.io/](https://systats.github.io/linear_model/index.html)
- [Werde ein Data Head](https://dpunkt.de/produkt/werde-ein-data-head/)
- [Statistik: Eine Einführung mit interaktiven Elementen.](https://link.springer.com/book/10.1007/978-3-662-61912-4)

<a class="btn btn-primary btn-back-to-main" href=`r params$links$end_session`>Session beenden</a>
